{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN WITH TF-SLIM\n",
    "#### ALL CODES ARE FROM [HWALSUKLEE](https://github.com/hwalsuklee/tensorflow-mnist-cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PACKAGES LOADED\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import os\n",
    "from scipy import ndimage\n",
    "from six.moves import urllib\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "print (\"PACKAGES LOADED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN MODEL WITH TF-SLIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def CNN(inputs, _is_training=True):\n",
    "    x   = tf.reshape(inputs, [-1, 28, 28, 1])\n",
    "    batch_norm_params = {'is_training': _is_training, 'decay': 0.9, 'updates_collections': None}\n",
    "    net = slim.conv2d(x, 32, [5, 5], padding='SAME'\n",
    "                     , activation_fn       = tf.nn.relu\n",
    "                     , weights_initializer = tf.truncated_normal_initializer(stddev=0.01)\n",
    "                     , normalizer_fn       = slim.batch_norm\n",
    "                     , normalizer_params   = batch_norm_params\n",
    "                     , scope='conv1')\n",
    "    net = slim.max_pool2d(net, [2, 2], scope='pool1')\n",
    "    net = slim.conv2d(net, 64, [5, 5], scope='conv2')\n",
    "    net = slim.max_pool2d(net, [2, 2], scope='pool2')\n",
    "    net = slim.flatten(net, scope='flatten3')\n",
    "    net = slim.fully_connected(net, 1024\n",
    "                    , activation_fn       = tf.nn.relu\n",
    "                    , weights_initializer = tf.truncated_normal_initializer(stddev=0.01)\n",
    "                    , normalizer_fn       = slim.batch_norm\n",
    "                    , normalizer_params   = batch_norm_params\n",
    "                    , scope='fc4')\n",
    "    net = slim.dropout(net, keep_prob=0.7, is_training=_is_training, scope='dropout4')  \n",
    "    out = slim.fully_connected(net, 10, activation_fn=None, normalizer_fn=None, scope='fco')\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HANDLING MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# DATA URL\n",
    "SOURCE_URL      = 'http://yann.lecun.com/exdb/mnist/'\n",
    "DATA_DIRECTORY  = \"data\"\n",
    "# PARAMETERS FOR MNIST\n",
    "IMAGE_SIZE      = 28\n",
    "NUM_CHANNELS    = 1\n",
    "PIXEL_DEPTH     = 255\n",
    "NUM_LABELS      = 10\n",
    "VALIDATION_SIZE = 5000  # Size of the validation set.\n",
    "\n",
    "# DOWNLOAD MNIST DATA, IF NECESSARY\n",
    "def maybe_download(filename):\n",
    "    if not tf.gfile.Exists(DATA_DIRECTORY):\n",
    "        tf.gfile.MakeDirs(DATA_DIRECTORY)\n",
    "    filepath = os.path.join(DATA_DIRECTORY, filename)\n",
    "    if not tf.gfile.Exists(filepath):\n",
    "        filepath, _ = urllib.request.urlretrieve(SOURCE_URL + filename, filepath)\n",
    "        with tf.gfile.GFile(filepath) as f:\n",
    "            size = f.size()\n",
    "        print('Successfully downloaded', filename, size, 'bytes.')\n",
    "    return filepath\n",
    "\n",
    "# EXTRACT IMAGES\n",
    "def extract_data(filename, num_images):\n",
    "    with gzip.open(filename) as bytestream:\n",
    "        bytestream.read(16)\n",
    "        buf = bytestream.read(IMAGE_SIZE * IMAGE_SIZE * num_images * NUM_CHANNELS)\n",
    "        data = np.frombuffer(buf, dtype=np.uint8).astype(np.float32)\n",
    "        data = (data - (PIXEL_DEPTH / 2.0)) / PIXEL_DEPTH # -0.5~0.5\n",
    "        data = data.reshape(num_images, IMAGE_SIZE, IMAGE_SIZE, NUM_CHANNELS)\n",
    "        data = np.reshape(data, [num_images, -1])\n",
    "    return data # [image index, y, x, channels]\n",
    "\n",
    "# EXTRACT LABELS\n",
    "def extract_labels(filename, num_images):\n",
    "    with gzip.open(filename) as bytestream:\n",
    "        bytestream.read(8)\n",
    "        buf = bytestream.read(1 * num_images)\n",
    "        labels = np.frombuffer(buf, dtype=np.uint8).astype(np.int64)\n",
    "        num_labels_data = len(labels)\n",
    "        one_hot_encoding = np.zeros((num_labels_data,NUM_LABELS))\n",
    "        one_hot_encoding[np.arange(num_labels_data),labels] = 1\n",
    "        one_hot_encoding = np.reshape(one_hot_encoding, [-1, NUM_LABELS])\n",
    "    return one_hot_encoding\n",
    "\n",
    "# AUGMENT TRAINING DATA\n",
    "def expend_training_data(images, labels):\n",
    "    expanded_images = []\n",
    "    expanded_labels = []\n",
    "    j = 0 # counter\n",
    "    for x, y in zip(images, labels):\n",
    "        j = j+1\n",
    "        # APPEND ORIGINAL DATA\n",
    "        expanded_images.append(x)\n",
    "        expanded_labels.append(y)\n",
    "        # ASSUME MEDIAN COLOR TO BE BACKGROUND COLOR\n",
    "        bg_value = np.median(x) # this is regarded as background's value        \n",
    "        image = np.reshape(x, (-1, 28))\n",
    "\n",
    "        for i in range(4):\n",
    "            # ROTATE IMAGE\n",
    "            angle = np.random.randint(-15,15,1)\n",
    "            new_img = ndimage.rotate(image,angle,reshape=False, cval=bg_value)\n",
    "            # SHIFT IAMGE\n",
    "            shift = np.random.randint(-2, 2, 2)\n",
    "            new_img_ = ndimage.shift(new_img,shift, cval=bg_value)\n",
    "            # ADD TO THE LIST\n",
    "            expanded_images.append(np.reshape(new_img_, 784))\n",
    "            expanded_labels.append(y)\n",
    "    expanded_train_total_data = np.concatenate((expanded_images, expanded_labels), axis=1)\n",
    "    np.random.shuffle(expanded_train_total_data)\n",
    "    return expanded_train_total_data\n",
    "\n",
    "# PREPARE MNIST DATA\n",
    "def prepare_MNIST_data(use_data_augmentation=True):\n",
    "    # Get the data.\n",
    "    train_data_filename = maybe_download('train-images-idx3-ubyte.gz')\n",
    "    train_labels_filename = maybe_download('train-labels-idx1-ubyte.gz')\n",
    "    test_data_filename = maybe_download('t10k-images-idx3-ubyte.gz')\n",
    "    test_labels_filename = maybe_download('t10k-labels-idx1-ubyte.gz')\n",
    "    train_data = extract_data(train_data_filename, 60000)\n",
    "    train_labels = extract_labels(train_labels_filename, 60000)\n",
    "    test_data = extract_data(test_data_filename, 10000)\n",
    "    test_labels = extract_labels(test_labels_filename, 10000)\n",
    "    validation_data = train_data[:VALIDATION_SIZE, :]\n",
    "    validation_labels = train_labels[:VALIDATION_SIZE,:]\n",
    "    train_data = train_data[VALIDATION_SIZE:, :]\n",
    "    train_labels = train_labels[VALIDATION_SIZE:,:]\n",
    "    if use_data_augmentation:\n",
    "        train_total_data = expend_training_data(train_data, train_labels)\n",
    "    else:\n",
    "        train_total_data = np.concatenate((train_data, train_labels), axis=1)\n",
    "    train_size = train_total_data.shape[0]\n",
    "    return train_total_data, train_size, validation_data, validation_labels, test_data, test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONFIGURATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MODEL_DIRECTORY   = \"model/model.ckpt\"\n",
    "LOGS_DIRECTORY    = \"logs/train\"\n",
    "training_epochs   = 10\n",
    "TRAIN_BATCH_SIZE  = 50\n",
    "display_step      = 500\n",
    "validation_step   = 500\n",
    "TEST_BATCH_SIZE   = 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# PREPARE MNIST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " TYPE AND SHAPE OF [  train_total_data ] ARE <type 'numpy.ndarray'> and  (275000, 794)\n",
      " TYPE AND SHAPE OF [   validation_data ] ARE <type 'numpy.ndarray'> and    (5000, 784)\n",
      " TYPE AND SHAPE OF [ validation_labels ] ARE <type 'numpy.ndarray'> and     (5000, 10)\n",
      " TYPE AND SHAPE OF [         test_data ] ARE <type 'numpy.ndarray'> and   (10000, 784)\n",
      " TYPE AND SHAPE OF [       test_labels ] ARE <type 'numpy.ndarray'> and    (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "batch_size = TRAIN_BATCH_SIZE # BATCH SIZE (50)\n",
    "num_labels = NUM_LABELS       # NUMBER OF LABELS (10)\n",
    "train_total_data, train_size, validation_data, validation_labels \\\n",
    "    , test_data, test_labels = prepare_MNIST_data(True)\n",
    "# PRINT FUNCTION\n",
    "def print_np(x, str):\n",
    "    print (\" TYPE AND SHAPE OF [%18s ] ARE %s and %14s\" \n",
    "           % (str, type(x), x.shape,))\n",
    "print_np(train_total_data, 'train_total_data')\n",
    "print_np(validation_data, 'validation_data')\n",
    "print_np(validation_labels, 'validation_labels')\n",
    "print_np(test_data, 'test_data')\n",
    "print_np(test_labels, 'test_labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEFINE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-6-6a1297beaf2d>:9: softmax_cross_entropy (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.\n",
      "Instructions for updating:\n",
      "Use tf.losses.softmax_cross_entropy instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/losses/python/losses/loss_ops.py:394: compute_weighted_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.\n",
      "Instructions for updating:\n",
      "Use tf.losses.compute_weighted_loss instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/losses/python/losses/loss_ops.py:151: add_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.\n",
      "Instructions for updating:\n",
      "Use tf.losses.add_loss instead.\n",
      "MODEL DEFINED.\n"
     ]
    }
   ],
   "source": [
    "# PLACEHOLDERS\n",
    "x  = tf.placeholder(tf.float32, [None, 784])\n",
    "y_ = tf.placeholder(tf.float32, [None, 10]) #answer\n",
    "is_training = tf.placeholder(tf.bool, name='MODE')\n",
    "# CONVOLUTIONAL NEURAL NETWORK MODEL \n",
    "y = CNN(x, is_training)\n",
    "# DEFINE LOSS\n",
    "with tf.name_scope(\"LOSS\"):\n",
    "    loss = slim.losses.softmax_cross_entropy(y, y_)\n",
    "# DEFINE ACCURACY\n",
    "with tf.name_scope(\"ACC\"):\n",
    "    correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "# DEFINE OPTIMIZER\n",
    "with tf.name_scope(\"ADAM\"):\n",
    "    batch = tf.Variable(0)\n",
    "    learning_rate = tf.train.exponential_decay(\n",
    "        1e-4,               # LEARNING_RATE\n",
    "        batch * batch_size, # GLOBAL_STEP\n",
    "        train_size,         # DECAY_STEP\n",
    "        0.95,               # DECAY_RATE\n",
    "        staircase=True)     # LR = LEARNING_RATE*DECAY_RATE^(GLOBAL_STEP/DECAY_STEP)\n",
    "    train_step = tf.train.AdamOptimizer(learning_rate).minimize(loss,global_step=batch)\n",
    "    # 'batch' IS AUTOMATICALLY UPDATED AS WE CALL 'train_step'\n",
    "\n",
    "# SUMMARIES\n",
    "saver = tf.train.Saver()\n",
    "tf.summary.scalar('learning_rate', learning_rate)\n",
    "tf.summary.scalar('loss', loss)\n",
    "tf.summary.scalar('acc', accuracy)\n",
    "merged_summary_op = tf.summary.merge_all()\n",
    "summary_writer = tf.summary.FileWriter(LOGS_DIRECTORY, graph=tf.get_default_graph())\n",
    "print (\"MODEL DEFINED.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OPEN SESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess  = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer(), feed_dict={is_training: True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OPTIMIZE\n",
    "### FOR TESTING PURPOSES, SKIP THIS SECTION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [  1/ 10] Batch: [0000/5500] Training Acc: 0.12000\n",
      "Epoch: [  1/ 10] Batch: [0000/5500] Validation Acc: 0.16060\n",
      "  MODEL UPDATED TO [model/model.ckpt] VALIDATION ACC IS 0.16060\n",
      "Epoch: [  1/ 10] Batch: [0500/5500] Training Acc: 0.94000\n",
      "Epoch: [  1/ 10] Batch: [0500/5500] Validation Acc: 0.98500\n",
      "  MODEL UPDATED TO [model/model.ckpt] VALIDATION ACC IS 0.98500\n",
      "Epoch: [  1/ 10] Batch: [1000/5500] Training Acc: 1.00000\n",
      "Epoch: [  1/ 10] Batch: [1000/5500] Validation Acc: 0.98640\n",
      "  MODEL UPDATED TO [model/model.ckpt] VALIDATION ACC IS 0.98640\n",
      "Epoch: [  1/ 10] Batch: [1500/5500] Training Acc: 1.00000\n",
      "Epoch: [  1/ 10] Batch: [1500/5500] Validation Acc: 0.98840\n",
      "  MODEL UPDATED TO [model/model.ckpt] VALIDATION ACC IS 0.98840\n",
      "Epoch: [  1/ 10] Batch: [2000/5500] Training Acc: 1.00000\n",
      "Epoch: [  1/ 10] Batch: [2000/5500] Validation Acc: 0.99080\n",
      "  MODEL UPDATED TO [model/model.ckpt] VALIDATION ACC IS 0.99080\n",
      "Epoch: [  1/ 10] Batch: [2500/5500] Training Acc: 0.98000\n",
      "Epoch: [  1/ 10] Batch: [2500/5500] Validation Acc: 0.99240\n",
      "  MODEL UPDATED TO [model/model.ckpt] VALIDATION ACC IS 0.99240\n",
      "Epoch: [  1/ 10] Batch: [3000/5500] Training Acc: 0.96000\n",
      "Epoch: [  1/ 10] Batch: [3000/5500] Validation Acc: 0.99160\n",
      "Epoch: [  1/ 10] Batch: [3500/5500] Training Acc: 1.00000\n",
      "Epoch: [  1/ 10] Batch: [3500/5500] Validation Acc: 0.99200\n",
      "Epoch: [  1/ 10] Batch: [4000/5500] Training Acc: 1.00000\n",
      "Epoch: [  1/ 10] Batch: [4000/5500] Validation Acc: 0.99360\n",
      "  MODEL UPDATED TO [model/model.ckpt] VALIDATION ACC IS 0.99360\n",
      "Epoch: [  1/ 10] Batch: [4500/5500] Training Acc: 1.00000\n",
      "Epoch: [  1/ 10] Batch: [4500/5500] Validation Acc: 0.99180\n",
      "Epoch: [  1/ 10] Batch: [5000/5500] Training Acc: 1.00000\n",
      "Epoch: [  1/ 10] Batch: [5000/5500] Validation Acc: 0.99240\n",
      "Epoch: [  2/ 10] Batch: [0000/5500] Training Acc: 0.98000\n",
      "Epoch: [  2/ 10] Batch: [0000/5500] Validation Acc: 0.99300\n",
      "Epoch: [  2/ 10] Batch: [0500/5500] Training Acc: 1.00000\n",
      "Epoch: [  2/ 10] Batch: [0500/5500] Validation Acc: 0.99240\n",
      "Epoch: [  2/ 10] Batch: [1000/5500] Training Acc: 1.00000\n",
      "Epoch: [  2/ 10] Batch: [1000/5500] Validation Acc: 0.99400\n",
      "  MODEL UPDATED TO [model/model.ckpt] VALIDATION ACC IS 0.99400\n",
      "Epoch: [  2/ 10] Batch: [1500/5500] Training Acc: 1.00000\n",
      "Epoch: [  2/ 10] Batch: [1500/5500] Validation Acc: 0.99380\n",
      "Epoch: [  2/ 10] Batch: [2000/5500] Training Acc: 1.00000\n",
      "Epoch: [  2/ 10] Batch: [2000/5500] Validation Acc: 0.99400\n",
      "Epoch: [  2/ 10] Batch: [2500/5500] Training Acc: 1.00000\n",
      "Epoch: [  2/ 10] Batch: [2500/5500] Validation Acc: 0.99460\n",
      "  MODEL UPDATED TO [model/model.ckpt] VALIDATION ACC IS 0.99460\n",
      "Epoch: [  2/ 10] Batch: [3000/5500] Training Acc: 0.98000\n",
      "Epoch: [  2/ 10] Batch: [3000/5500] Validation Acc: 0.99360\n",
      "Epoch: [  2/ 10] Batch: [3500/5500] Training Acc: 0.98000\n",
      "Epoch: [  2/ 10] Batch: [3500/5500] Validation Acc: 0.99460\n",
      "Epoch: [  2/ 10] Batch: [4000/5500] Training Acc: 1.00000\n",
      "Epoch: [  2/ 10] Batch: [4000/5500] Validation Acc: 0.99380\n",
      "Epoch: [  2/ 10] Batch: [4500/5500] Training Acc: 1.00000\n",
      "Epoch: [  2/ 10] Batch: [4500/5500] Validation Acc: 0.99380\n",
      "Epoch: [  2/ 10] Batch: [5000/5500] Training Acc: 0.98000\n",
      "Epoch: [  2/ 10] Batch: [5000/5500] Validation Acc: 0.99320\n",
      "Epoch: [  3/ 10] Batch: [0000/5500] Training Acc: 0.98000\n",
      "Epoch: [  3/ 10] Batch: [0000/5500] Validation Acc: 0.99420\n",
      "Epoch: [  3/ 10] Batch: [0500/5500] Training Acc: 1.00000\n",
      "Epoch: [  3/ 10] Batch: [0500/5500] Validation Acc: 0.99280\n",
      "Epoch: [  3/ 10] Batch: [1000/5500] Training Acc: 1.00000\n",
      "Epoch: [  3/ 10] Batch: [1000/5500] Validation Acc: 0.99440\n",
      "Epoch: [  3/ 10] Batch: [1500/5500] Training Acc: 1.00000\n",
      "Epoch: [  3/ 10] Batch: [1500/5500] Validation Acc: 0.99520\n",
      "  MODEL UPDATED TO [model/model.ckpt] VALIDATION ACC IS 0.99520\n",
      "Epoch: [  3/ 10] Batch: [2000/5500] Training Acc: 1.00000\n",
      "Epoch: [  3/ 10] Batch: [2000/5500] Validation Acc: 0.99400\n",
      "Epoch: [  3/ 10] Batch: [2500/5500] Training Acc: 0.98000\n",
      "Epoch: [  3/ 10] Batch: [2500/5500] Validation Acc: 0.99560\n",
      "  MODEL UPDATED TO [model/model.ckpt] VALIDATION ACC IS 0.99560\n",
      "Epoch: [  3/ 10] Batch: [3000/5500] Training Acc: 1.00000\n",
      "Epoch: [  3/ 10] Batch: [3000/5500] Validation Acc: 0.99520\n",
      "Epoch: [  3/ 10] Batch: [3500/5500] Training Acc: 0.98000\n",
      "Epoch: [  3/ 10] Batch: [3500/5500] Validation Acc: 0.99380\n",
      "Epoch: [  3/ 10] Batch: [4000/5500] Training Acc: 1.00000\n",
      "Epoch: [  3/ 10] Batch: [4000/5500] Validation Acc: 0.99540\n",
      "Epoch: [  3/ 10] Batch: [4500/5500] Training Acc: 0.96000\n",
      "Epoch: [  3/ 10] Batch: [4500/5500] Validation Acc: 0.99480\n",
      "Epoch: [  3/ 10] Batch: [5000/5500] Training Acc: 1.00000\n",
      "Epoch: [  3/ 10] Batch: [5000/5500] Validation Acc: 0.99460\n",
      "Epoch: [  4/ 10] Batch: [0000/5500] Training Acc: 1.00000\n",
      "Epoch: [  4/ 10] Batch: [0000/5500] Validation Acc: 0.99540\n",
      "Epoch: [  4/ 10] Batch: [0500/5500] Training Acc: 1.00000\n",
      "Epoch: [  4/ 10] Batch: [0500/5500] Validation Acc: 0.99520\n",
      "Epoch: [  4/ 10] Batch: [1000/5500] Training Acc: 1.00000\n",
      "Epoch: [  4/ 10] Batch: [1000/5500] Validation Acc: 0.99560\n",
      "Epoch: [  4/ 10] Batch: [1500/5500] Training Acc: 1.00000\n",
      "Epoch: [  4/ 10] Batch: [1500/5500] Validation Acc: 0.99580\n",
      "  MODEL UPDATED TO [model/model.ckpt] VALIDATION ACC IS 0.99580\n",
      "Epoch: [  4/ 10] Batch: [2000/5500] Training Acc: 1.00000\n",
      "Epoch: [  4/ 10] Batch: [2000/5500] Validation Acc: 0.99520\n",
      "Epoch: [  4/ 10] Batch: [2500/5500] Training Acc: 1.00000\n",
      "Epoch: [  4/ 10] Batch: [2500/5500] Validation Acc: 0.99440\n",
      "Epoch: [  4/ 10] Batch: [3000/5500] Training Acc: 1.00000\n",
      "Epoch: [  4/ 10] Batch: [3000/5500] Validation Acc: 0.99620\n",
      "  MODEL UPDATED TO [model/model.ckpt] VALIDATION ACC IS 0.99620\n",
      "Epoch: [  4/ 10] Batch: [3500/5500] Training Acc: 1.00000\n",
      "Epoch: [  4/ 10] Batch: [3500/5500] Validation Acc: 0.99500\n",
      "Epoch: [  4/ 10] Batch: [4000/5500] Training Acc: 1.00000\n",
      "Epoch: [  4/ 10] Batch: [4000/5500] Validation Acc: 0.99360\n",
      "Epoch: [  4/ 10] Batch: [4500/5500] Training Acc: 1.00000\n",
      "Epoch: [  4/ 10] Batch: [4500/5500] Validation Acc: 0.99400\n",
      "Epoch: [  4/ 10] Batch: [5000/5500] Training Acc: 1.00000\n",
      "Epoch: [  4/ 10] Batch: [5000/5500] Validation Acc: 0.99600\n",
      "Epoch: [  5/ 10] Batch: [0000/5500] Training Acc: 0.98000\n",
      "Epoch: [  5/ 10] Batch: [0000/5500] Validation Acc: 0.99500\n",
      "Epoch: [  5/ 10] Batch: [0500/5500] Training Acc: 1.00000\n",
      "Epoch: [  5/ 10] Batch: [0500/5500] Validation Acc: 0.99640\n",
      "  MODEL UPDATED TO [model/model.ckpt] VALIDATION ACC IS 0.99640\n",
      "Epoch: [  5/ 10] Batch: [1000/5500] Training Acc: 1.00000\n",
      "Epoch: [  5/ 10] Batch: [1000/5500] Validation Acc: 0.99640\n",
      "Epoch: [  5/ 10] Batch: [1500/5500] Training Acc: 1.00000\n",
      "Epoch: [  5/ 10] Batch: [1500/5500] Validation Acc: 0.99480\n",
      "Epoch: [  5/ 10] Batch: [2000/5500] Training Acc: 0.98000\n",
      "Epoch: [  5/ 10] Batch: [2000/5500] Validation Acc: 0.99580\n",
      "Epoch: [  5/ 10] Batch: [2500/5500] Training Acc: 1.00000\n",
      "Epoch: [  5/ 10] Batch: [2500/5500] Validation Acc: 0.99580\n",
      "Epoch: [  5/ 10] Batch: [3000/5500] Training Acc: 1.00000\n",
      "Epoch: [  5/ 10] Batch: [3000/5500] Validation Acc: 0.99620\n",
      "Epoch: [  5/ 10] Batch: [3500/5500] Training Acc: 1.00000\n",
      "Epoch: [  5/ 10] Batch: [3500/5500] Validation Acc: 0.99600\n",
      "Epoch: [  5/ 10] Batch: [4000/5500] Training Acc: 1.00000\n",
      "Epoch: [  5/ 10] Batch: [4000/5500] Validation Acc: 0.99520\n",
      "Epoch: [  5/ 10] Batch: [4500/5500] Training Acc: 1.00000\n",
      "Epoch: [  5/ 10] Batch: [4500/5500] Validation Acc: 0.99460\n",
      "Epoch: [  5/ 10] Batch: [5000/5500] Training Acc: 1.00000\n",
      "Epoch: [  5/ 10] Batch: [5000/5500] Validation Acc: 0.99640\n",
      "Epoch: [  6/ 10] Batch: [0000/5500] Training Acc: 1.00000\n",
      "Epoch: [  6/ 10] Batch: [0000/5500] Validation Acc: 0.99620\n",
      "Epoch: [  6/ 10] Batch: [0500/5500] Training Acc: 1.00000\n",
      "Epoch: [  6/ 10] Batch: [0500/5500] Validation Acc: 0.99580\n",
      "Epoch: [  6/ 10] Batch: [1000/5500] Training Acc: 1.00000\n",
      "Epoch: [  6/ 10] Batch: [1000/5500] Validation Acc: 0.99600\n",
      "Epoch: [  6/ 10] Batch: [1500/5500] Training Acc: 1.00000\n",
      "Epoch: [  6/ 10] Batch: [1500/5500] Validation Acc: 0.99640\n",
      "Epoch: [  6/ 10] Batch: [2000/5500] Training Acc: 0.98000\n",
      "Epoch: [  6/ 10] Batch: [2000/5500] Validation Acc: 0.99520\n",
      "Epoch: [  6/ 10] Batch: [2500/5500] Training Acc: 1.00000\n",
      "Epoch: [  6/ 10] Batch: [2500/5500] Validation Acc: 0.99560\n",
      "Epoch: [  6/ 10] Batch: [3000/5500] Training Acc: 1.00000\n",
      "Epoch: [  6/ 10] Batch: [3000/5500] Validation Acc: 0.99660\n",
      "  MODEL UPDATED TO [model/model.ckpt] VALIDATION ACC IS 0.99660\n",
      "Epoch: [  6/ 10] Batch: [3500/5500] Training Acc: 1.00000\n",
      "Epoch: [  6/ 10] Batch: [3500/5500] Validation Acc: 0.99460\n",
      "Epoch: [  6/ 10] Batch: [4000/5500] Training Acc: 1.00000\n",
      "Epoch: [  6/ 10] Batch: [4000/5500] Validation Acc: 0.99600\n",
      "Epoch: [  6/ 10] Batch: [4500/5500] Training Acc: 1.00000\n",
      "Epoch: [  6/ 10] Batch: [4500/5500] Validation Acc: 0.99620\n",
      "Epoch: [  6/ 10] Batch: [5000/5500] Training Acc: 1.00000\n",
      "Epoch: [  6/ 10] Batch: [5000/5500] Validation Acc: 0.99540\n",
      "Epoch: [  7/ 10] Batch: [0000/5500] Training Acc: 1.00000\n",
      "Epoch: [  7/ 10] Batch: [0000/5500] Validation Acc: 0.99420\n",
      "Epoch: [  7/ 10] Batch: [0500/5500] Training Acc: 1.00000\n",
      "Epoch: [  7/ 10] Batch: [0500/5500] Validation Acc: 0.99600\n",
      "Epoch: [  7/ 10] Batch: [1000/5500] Training Acc: 1.00000\n",
      "Epoch: [  7/ 10] Batch: [1000/5500] Validation Acc: 0.99600\n",
      "Epoch: [  7/ 10] Batch: [1500/5500] Training Acc: 1.00000\n",
      "Epoch: [  7/ 10] Batch: [1500/5500] Validation Acc: 0.99580\n",
      "Epoch: [  7/ 10] Batch: [2000/5500] Training Acc: 1.00000\n",
      "Epoch: [  7/ 10] Batch: [2000/5500] Validation Acc: 0.99620\n",
      "Epoch: [  7/ 10] Batch: [2500/5500] Training Acc: 1.00000\n",
      "Epoch: [  7/ 10] Batch: [2500/5500] Validation Acc: 0.99560\n",
      "Epoch: [  7/ 10] Batch: [3000/5500] Training Acc: 1.00000\n",
      "Epoch: [  7/ 10] Batch: [3000/5500] Validation Acc: 0.99620\n",
      "Epoch: [  7/ 10] Batch: [3500/5500] Training Acc: 1.00000\n",
      "Epoch: [  7/ 10] Batch: [3500/5500] Validation Acc: 0.99620\n",
      "Epoch: [  7/ 10] Batch: [4000/5500] Training Acc: 1.00000\n",
      "Epoch: [  7/ 10] Batch: [4000/5500] Validation Acc: 0.99500\n",
      "Epoch: [  7/ 10] Batch: [4500/5500] Training Acc: 1.00000\n",
      "Epoch: [  7/ 10] Batch: [4500/5500] Validation Acc: 0.99660\n",
      "Epoch: [  7/ 10] Batch: [5000/5500] Training Acc: 1.00000\n",
      "Epoch: [  7/ 10] Batch: [5000/5500] Validation Acc: 0.99620\n",
      "Epoch: [  8/ 10] Batch: [0000/5500] Training Acc: 0.98000\n",
      "Epoch: [  8/ 10] Batch: [0000/5500] Validation Acc: 0.99600\n",
      "Epoch: [  8/ 10] Batch: [0500/5500] Training Acc: 1.00000\n",
      "Epoch: [  8/ 10] Batch: [0500/5500] Validation Acc: 0.99620\n",
      "Epoch: [  8/ 10] Batch: [1000/5500] Training Acc: 1.00000\n",
      "Epoch: [  8/ 10] Batch: [1000/5500] Validation Acc: 0.99640\n",
      "Epoch: [  8/ 10] Batch: [1500/5500] Training Acc: 1.00000\n",
      "Epoch: [  8/ 10] Batch: [1500/5500] Validation Acc: 0.99520\n",
      "Epoch: [  8/ 10] Batch: [2000/5500] Training Acc: 1.00000\n",
      "Epoch: [  8/ 10] Batch: [2000/5500] Validation Acc: 0.99560\n",
      "Epoch: [  8/ 10] Batch: [2500/5500] Training Acc: 1.00000\n",
      "Epoch: [  8/ 10] Batch: [2500/5500] Validation Acc: 0.99600\n",
      "Epoch: [  8/ 10] Batch: [3000/5500] Training Acc: 1.00000\n",
      "Epoch: [  8/ 10] Batch: [3000/5500] Validation Acc: 0.99620\n",
      "Epoch: [  8/ 10] Batch: [3500/5500] Training Acc: 1.00000\n",
      "Epoch: [  8/ 10] Batch: [3500/5500] Validation Acc: 0.99600\n",
      "Epoch: [  8/ 10] Batch: [4000/5500] Training Acc: 1.00000\n",
      "Epoch: [  8/ 10] Batch: [4000/5500] Validation Acc: 0.99680\n",
      "  MODEL UPDATED TO [model/model.ckpt] VALIDATION ACC IS 0.99680\n",
      "Epoch: [  8/ 10] Batch: [4500/5500] Training Acc: 1.00000\n",
      "Epoch: [  8/ 10] Batch: [4500/5500] Validation Acc: 0.99540\n",
      "Epoch: [  8/ 10] Batch: [5000/5500] Training Acc: 1.00000\n",
      "Epoch: [  8/ 10] Batch: [5000/5500] Validation Acc: 0.99660\n",
      "Epoch: [  9/ 10] Batch: [0000/5500] Training Acc: 1.00000\n",
      "Epoch: [  9/ 10] Batch: [0000/5500] Validation Acc: 0.99600\n",
      "Epoch: [  9/ 10] Batch: [0500/5500] Training Acc: 1.00000\n",
      "Epoch: [  9/ 10] Batch: [0500/5500] Validation Acc: 0.99660\n",
      "Epoch: [  9/ 10] Batch: [1000/5500] Training Acc: 1.00000\n",
      "Epoch: [  9/ 10] Batch: [1000/5500] Validation Acc: 0.99600\n",
      "Epoch: [  9/ 10] Batch: [1500/5500] Training Acc: 1.00000\n",
      "Epoch: [  9/ 10] Batch: [1500/5500] Validation Acc: 0.99620\n",
      "Epoch: [  9/ 10] Batch: [2000/5500] Training Acc: 1.00000\n",
      "Epoch: [  9/ 10] Batch: [2000/5500] Validation Acc: 0.99660\n",
      "Epoch: [  9/ 10] Batch: [2500/5500] Training Acc: 1.00000\n",
      "Epoch: [  9/ 10] Batch: [2500/5500] Validation Acc: 0.99600\n",
      "Epoch: [  9/ 10] Batch: [3000/5500] Training Acc: 1.00000\n",
      "Epoch: [  9/ 10] Batch: [3000/5500] Validation Acc: 0.99660\n",
      "Epoch: [  9/ 10] Batch: [3500/5500] Training Acc: 0.98000\n",
      "Epoch: [  9/ 10] Batch: [3500/5500] Validation Acc: 0.99620\n",
      "Epoch: [  9/ 10] Batch: [4000/5500] Training Acc: 1.00000\n",
      "Epoch: [  9/ 10] Batch: [4000/5500] Validation Acc: 0.99680\n",
      "  MODEL UPDATED TO [model/model.ckpt] VALIDATION ACC IS 0.99680\n",
      "Epoch: [  9/ 10] Batch: [4500/5500] Training Acc: 1.00000\n",
      "Epoch: [  9/ 10] Batch: [4500/5500] Validation Acc: 0.99620\n",
      "Epoch: [  9/ 10] Batch: [5000/5500] Training Acc: 1.00000\n",
      "Epoch: [  9/ 10] Batch: [5000/5500] Validation Acc: 0.99600\n",
      "Epoch: [ 10/ 10] Batch: [0000/5500] Training Acc: 1.00000\n",
      "Epoch: [ 10/ 10] Batch: [0000/5500] Validation Acc: 0.99580\n",
      "Epoch: [ 10/ 10] Batch: [0500/5500] Training Acc: 1.00000\n",
      "Epoch: [ 10/ 10] Batch: [0500/5500] Validation Acc: 0.99580\n",
      "Epoch: [ 10/ 10] Batch: [1000/5500] Training Acc: 1.00000\n",
      "Epoch: [ 10/ 10] Batch: [1000/5500] Validation Acc: 0.99540\n",
      "Epoch: [ 10/ 10] Batch: [1500/5500] Training Acc: 1.00000\n",
      "Epoch: [ 10/ 10] Batch: [1500/5500] Validation Acc: 0.99500\n",
      "Epoch: [ 10/ 10] Batch: [2000/5500] Training Acc: 1.00000\n",
      "Epoch: [ 10/ 10] Batch: [2000/5500] Validation Acc: 0.99640\n",
      "Epoch: [ 10/ 10] Batch: [2500/5500] Training Acc: 1.00000\n",
      "Epoch: [ 10/ 10] Batch: [2500/5500] Validation Acc: 0.99640\n",
      "Epoch: [ 10/ 10] Batch: [3000/5500] Training Acc: 1.00000\n",
      "Epoch: [ 10/ 10] Batch: [3000/5500] Validation Acc: 0.99680\n",
      "Epoch: [ 10/ 10] Batch: [3500/5500] Training Acc: 1.00000\n",
      "Epoch: [ 10/ 10] Batch: [3500/5500] Validation Acc: 0.99600\n",
      "Epoch: [ 10/ 10] Batch: [4000/5500] Training Acc: 1.00000\n",
      "Epoch: [ 10/ 10] Batch: [4000/5500] Validation Acc: 0.99660\n",
      "Epoch: [ 10/ 10] Batch: [4500/5500] Training Acc: 1.00000\n",
      "Epoch: [ 10/ 10] Batch: [4500/5500] Validation Acc: 0.99580\n",
      "Epoch: [ 10/ 10] Batch: [5000/5500] Training Acc: 1.00000\n",
      "Epoch: [ 10/ 10] Batch: [5000/5500] Validation Acc: 0.99560\n",
      "OPTIMIZATION FINISHED\n"
     ]
    }
   ],
   "source": [
    "# MAXIMUM ACCURACY\n",
    "max_acc = 0.\n",
    "# LOOP\n",
    "for epoch in range(training_epochs): # training_epochs: 10\n",
    "    # RANDOM SHUFFLE\n",
    "    np.random.shuffle(train_total_data)\n",
    "    train_data_   = train_total_data[:, :-num_labels]\n",
    "    train_labels_ = train_total_data[:, -num_labels:]\n",
    "    # ITERATIONS\n",
    "    total_batch = int(train_size / batch_size)\n",
    "    for iteration in range(total_batch):\n",
    "        # GET CURRENT MINI-BATCH\n",
    "        offset = (iteration * batch_size) % (train_size)\n",
    "        batch_xs = train_data_[offset:(offset + batch_size), :]\n",
    "        batch_ys = train_labels_[offset:(offset + batch_size), :]\n",
    "        # OPTIMIZE\n",
    "        _, train_accuracy, summary = sess.run([train_step, accuracy, merged_summary_op]\n",
    "                                    , feed_dict={x: batch_xs, y_: batch_ys, is_training: True})\n",
    "        # WRITE LOG\n",
    "        summary_writer.add_summary(summary, epoch*total_batch + iteration)\n",
    "\n",
    "        # DISPLAY\n",
    "        if iteration % display_step == 0:\n",
    "            print(\"Epoch: [%3d/%3d] Batch: [%04d/%04d] Training Acc: %.5f\" \n",
    "                  % (epoch + 1, training_epochs, iteration, total_batch, train_accuracy))\n",
    "\n",
    "        # GET ACCURACY FOR THE VALIDATION DATA\n",
    "        if iteration % validation_step == 0:\n",
    "            validation_accuracy = sess.run(accuracy,\n",
    "            feed_dict={x: validation_data, y_: validation_labels, is_training: False})\n",
    "            print(\"Epoch: [%3d/%3d] Batch: [%04d/%04d] Validation Acc: %.5f\" \n",
    "                  % (epoch + 1, training_epochs, iteration, total_batch, validation_accuracy))\n",
    "        # SAVE THE MODEL WITH HIGEST VALIDATION ACCURACY\n",
    "        if validation_accuracy > max_acc:\n",
    "            max_acc = validation_accuracy\n",
    "            save_path = saver.save(sess, MODEL_DIRECTORY)\n",
    "            print(\"  MODEL UPDATED TO [%s] VALIDATION ACC IS %.5f\" \n",
    "                  % (save_path, validation_accuracy))\n",
    "print(\"OPTIMIZATION FINISHED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMPUTE TEST ACCURACY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST ACCURACY IS: 0.9961\n"
     ]
    }
   ],
   "source": [
    "# RESTORE SAVED NETWORK\n",
    "saver.restore(sess, MODEL_DIRECTORY)\n",
    "\n",
    "# COMPUTE ACCURACY FOR TEST DATA\n",
    "test_size   = test_labels.shape[0]\n",
    "total_batch = int(test_size / batch_size)\n",
    "acc_buffer  = []\n",
    "for i in range(total_batch):\n",
    "    offset = (i * batch_size) % (test_size)\n",
    "    batch_xs = test_data[offset:(offset + batch_size), :]\n",
    "    batch_ys = test_labels[offset:(offset + batch_size), :]\n",
    "    y_final = sess.run(y, feed_dict={x: batch_xs, y_: batch_ys, is_training: False})\n",
    "    correct_prediction = np.equal(np.argmax(y_final, 1), np.argmax(batch_ys, 1))\n",
    "    acc_buffer.append(np.sum(correct_prediction.astype(float)) / batch_size)\n",
    "print(\"TEST ACCURACY IS: %.4f\" % np.mean(acc_buffer))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
