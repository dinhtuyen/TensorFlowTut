{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SIMPLE CHAR-RNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TENSORFLOW VERSION IS 1.1.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.contrib import rnn\n",
    "tf.set_random_seed(0)  \n",
    "print (\"TENSORFLOW VERSION IS %s\" % (tf.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEFINE TRAINING SEQUENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLLOWING IS OUR TRAINING SEQUENCE:\n",
      "Perfection is achieved, not when there is nothing more to add, but when there is nothing left to take away.\n"
     ]
    }
   ],
   "source": [
    "quote1 = (\"If you want to build a ship, \"\n",
    "          \"don't drum up people to collect wood and don't assign them tasks and work,\"\n",
    "          \" but rather teach them to long for the endless immensity of the sea.\")\n",
    "quote2 = (\"Perfection is achieved, \"\n",
    "          \"not when there is nothing more to add, \"\n",
    "          \"but when there is nothing left to take away.\")\n",
    "sentence = quote2\n",
    "print (\"FOLLOWING IS OUR TRAINING SEQUENCE:\")\n",
    "print (sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEFINE VOCABULARY AND DICTIONARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VOCABULARY: \n",
      "[' ', ',', '.', 'P', 'a', 'c', 'b', 'e', 'd', 'g', 'f', 'i', 'h', 'k', 'm', 'l', 'o', 'n', 's', 'r', 'u', 't', 'w', 'v', 'y']\n",
      "DICTIONARY: \n",
      "{' ': 0, ',': 1, '.': 2, 'P': 3, 'a': 4, 'c': 5, 'b': 6, 'e': 7, 'd': 8, 'g': 9, 'f': 10, 'i': 11, 'h': 12, 'k': 13, 'm': 14, 'l': 15, 'o': 16, 'n': 17, 's': 18, 'r': 19, 'u': 20, 't': 21, 'w': 22, 'v': 23, 'y': 24}\n"
     ]
    }
   ],
   "source": [
    "char_set = list(set(sentence))\n",
    "char_dic = {w: i for i, w in enumerate(char_set)}\n",
    "print (\"VOCABULARY: \")\n",
    "print (char_set)\n",
    "print (\"DICTIONARY: \")\n",
    "print (char_dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VOCAB: NUMBER => CHAR / DICTIONARY: CHAR => NUMBER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONFIGURE NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_DIM IS [25]\n"
     ]
    }
   ],
   "source": [
    "data_dim        = len(char_set)\n",
    "num_classes     = len(char_set)\n",
    "hidden_size     = 64\n",
    "sequence_length = 10  # Any arbitrary number \n",
    "print (\"DATA_DIM IS [%d]\" % (data_dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SET TRAINING BATCHES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_np(_name, _x):\n",
    "    print(\"TYPE  OF [%s] is [%s]\" % (_name, type(_x)))\n",
    "    print(\"SHAPE OF [%s] is %s\" % (_name, _x.shape,))\n",
    "def print_list(_name, _x):\n",
    "    print(\"TYPE   OF [%s] is [%s]\" % (_name, type(_x)))\n",
    "    print(\"LENGTH OF [%s] is %s\" % (_name, len(_x)))\n",
    "    print(\"%s[0] LOOKS LIKE %s\" % (_name, _x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0/ 107] [Perfection]=>[erfection ]\n",
      "            [3, 7, 19, 10, 7, 5, 21, 11, 16, 17] => [7, 19, 10, 7, 5, 21, 11, 16, 17, 0]\n",
      "[   1/ 107] [erfection ]=>[rfection i]\n",
      "            [7, 19, 10, 7, 5, 21, 11, 16, 17, 0] => [19, 10, 7, 5, 21, 11, 16, 17, 0, 11]\n",
      "[   2/ 107] [rfection i]=>[fection is]\n",
      "            [19, 10, 7, 5, 21, 11, 16, 17, 0, 11] => [10, 7, 5, 21, 11, 16, 17, 0, 11, 18]\n",
      "[   3/ 107] [fection is]=>[ection is ]\n",
      "            [10, 7, 5, 21, 11, 16, 17, 0, 11, 18] => [7, 5, 21, 11, 16, 17, 0, 11, 18, 0]\n",
      "[   4/ 107] [ection is ]=>[ction is a]\n",
      "            [7, 5, 21, 11, 16, 17, 0, 11, 18, 0] => [5, 21, 11, 16, 17, 0, 11, 18, 0, 4]\n",
      "TYPE   OF [dataX] is [<type 'list'>]\n",
      "LENGTH OF [dataX] is 97\n",
      "dataX[0] LOOKS LIKE [3, 7, 19, 10, 7, 5, 21, 11, 16, 17]\n",
      "TYPE   OF [dataY] is [<type 'list'>]\n",
      "LENGTH OF [dataY] is 97\n",
      "dataY[0] LOOKS LIKE [7, 19, 10, 7, 5, 21, 11, 16, 17, 0]\n"
     ]
    }
   ],
   "source": [
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(0, len(sentence) - sequence_length):\n",
    "    x_str = sentence[i:i + sequence_length]\n",
    "    y_str = sentence[i + 1: i + sequence_length + 1]\n",
    "    x = [char_dic[c] for c in x_str]  # x str to index\n",
    "    y = [char_dic[c] for c in y_str]  # y str to index\n",
    "    dataX.append(x)\n",
    "    dataY.append(y)\n",
    "    if i < 5:\n",
    "        print (\"[%4d/%4d] [%s]=>[%s]\" % (i, len(sentence), x_str, y_str))\n",
    "        print (\"%s%s => %s\" % (' '*12, x, y))\n",
    "print_list('dataX', dataX)\n",
    "print_list('dataY', dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     'NDATA' IS 97\n",
      "'BATCH_SIZE' IS 512\n"
     ]
    }
   ],
   "source": [
    "ndata      = len(dataX)\n",
    "batch_size = 512\n",
    "print (\"     'NDATA' IS %d\" % (ndata))\n",
    "print (\"'BATCH_SIZE' IS %d\" % (batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEFINE PLACEHOLDERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'sequence_length' IS [10]\n",
      "    'num_classes' IS [25]\n",
      "'X' LOOKS LIKE \n",
      "   [Tensor(\"Placeholder:0\", shape=(?, 10), dtype=int32)]\n",
      "'X_OH' LOOKS LIKE \n",
      "   [Tensor(\"one_hot:0\", shape=(?, 10, 25), dtype=float32)]\n",
      "'Y' LOOKS LIKE \n",
      "   [Tensor(\"Placeholder_1:0\", shape=(?, 10), dtype=int32)]\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(tf.int32, [None, sequence_length])\n",
    "X_OH = tf.one_hot(X, num_classes)\n",
    "Y = tf.placeholder(tf.int32, [None, sequence_length])\n",
    "print (\"'sequence_length' IS [%d]\" % (sequence_length))\n",
    "print (\"    'num_classes' IS [%d]\" % (num_classes))\n",
    "print(\"'X' LOOKS LIKE \\n   [%s]\" % (X))  \n",
    "print(\"'X_OH' LOOKS LIKE \\n   [%s]\" % (X_OH))\n",
    "print(\"'Y' LOOKS LIKE \\n   [%s]\" % (Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEFINE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_hiddens   LOOKS LIKE [Tensor(\"CHAR-RNN/fully_connected/Relu:0\", shape=(?, 10, 64), dtype=float32)]\n",
      "_rnnouts   LOOKS LIKE [Tensor(\"CHAR-RNN/rnn/transpose:0\", shape=(?, 10, 64), dtype=float32)]\n",
      "_denseouts LOOKS LIKE [Tensor(\"CHAR-RNN/fully_connected_1/BiasAdd:0\", shape=(?, 10, 25), dtype=float32)]\n",
      "outputs    LOOKS LIKE [Tensor(\"CHAR-RNN/Reshape:0\", shape=(512, 10, 25), dtype=float32)]\n",
      "MODEL DEFINED.\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope('CHAR-RNN', reuse=False):\n",
    "    cell = rnn.BasicLSTMCell(hidden_size, state_is_tuple=True, reuse=False)\n",
    "    # cell = rnn.MultiRNNCell([cell]*2, state_is_tuple=True) # BUG IN TF1.1..\n",
    "    # DYNAMIC RNN WITH FULLY CONNECTED LAYER\n",
    "    _hiddens  = tf.contrib.layers.fully_connected(X_OH, hidden_size, activation_fn=tf.nn.relu)\n",
    "    _rnnouts, _states = tf.nn.dynamic_rnn(cell, _hiddens, dtype=tf.float32)\n",
    "    _denseouts = tf.contrib.layers.fully_connected(_rnnouts, num_classes, activation_fn=None)\n",
    "    # RESHAPE FOR SEQUNCE LOSS\n",
    "    outputs = tf.reshape(_denseouts, [batch_size, sequence_length, num_classes])\n",
    "    \n",
    "print (\"_hiddens   LOOKS LIKE [%s]\" % (_hiddens))\n",
    "print (\"_rnnouts   LOOKS LIKE [%s]\" % (_rnnouts))\n",
    "print (\"_denseouts LOOKS LIKE [%s]\" % (_denseouts))\n",
    "print (\"outputs    LOOKS LIKE [%s]\" % (outputs))\n",
    "print (\"MODEL DEFINED.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEFINE TF FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights LOOKS LIKE [Tensor(\"ones:0\", shape=(512, 10), dtype=float32)]\n",
      "outputs LOOKS LIKE [Tensor(\"CHAR-RNN/Reshape:0\", shape=(512, 10, 25), dtype=float32)]\n",
      "Y       LOOKS LIKE [Tensor(\"Placeholder_1:0\", shape=(?, 10), dtype=int32)]\n"
     ]
    }
   ],
   "source": [
    "weights  = tf.ones([batch_size, sequence_length]) # EQUAL WEIGHTS\n",
    "seq_loss = tf.contrib.seq2seq.sequence_loss(\n",
    "    logits=outputs, targets=Y, weights=weights) # THIS IS A CLASSIFICATION LOSS\n",
    "print (\"weights LOOKS LIKE [%s]\" % (weights))\n",
    "print (\"outputs LOOKS LIKE [%s]\" % (outputs))\n",
    "print (\"Y       LOOKS LIKE [%s]\" % (Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FUNCTIONS DEFINED.\n"
     ]
    }
   ],
   "source": [
    "loss  = tf.reduce_mean(seq_loss)\n",
    "optm  = tf.train.AdamOptimizer(learning_rate=0.01).minimize(loss)\n",
    "print (\"FUNCTIONS DEFINED.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OPTIMIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    0/2000] loss_val: 3.21126 \n",
      "[  200/2000] loss_val: 0.17822 \n",
      "[  400/2000] loss_val: 0.16920 \n",
      "[  600/2000] loss_val: 0.17338 \n",
      "[  800/2000] loss_val: 0.16925 \n",
      "[ 1000/2000] loss_val: 0.17624 \n",
      "[ 1200/2000] loss_val: 0.17331 \n",
      "[ 1400/2000] loss_val: 0.17291 \n",
      "[ 1600/2000] loss_val: 0.17237 \n",
      "[ 1800/2000] loss_val: 0.16771 \n"
     ]
    }
   ],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.Session(config=config)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "MAXITER = 2000\n",
    "for i in range(MAXITER):\n",
    "    randidx = np.random.randint(low=0, high=ndata, size=batch_size)\n",
    "    batchX = [dataX[iii] for iii in randidx]\n",
    "    batchY = [dataY[iii] for iii in randidx]\n",
    "    feeds = {X: batchX, Y: batchY}\n",
    "    _, loss_val, results = sess.run(\n",
    "        [optm, loss, outputs], feed_dict=feeds)\n",
    "    if (i%200) == 0:\n",
    "        print (\"[%5d/%d] loss_val: %.5f \" % (i, MAXITER, loss_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BATCH LOOKS LIKE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LENGTH OF BATCHX IS 512\n",
      "batchX[0] looks like [21, 12, 7, 19, 7, 0, 11, 18, 0, 17]\n",
      "LENGTH OF BATCHY IS 512\n",
      "batchY[0] looks like [12, 7, 19, 7, 0, 11, 18, 0, 17, 16]\n"
     ]
    }
   ],
   "source": [
    "print (\"LENGTH OF BATCHX IS %d\" % (len(batchX)))\n",
    "print (\"batchX[0] looks like %s\" % (batchX[0]))\n",
    "print (\"LENGTH OF BATCHY IS %d\" % (len(batchY)))\n",
    "print (\"batchY[0] looks like %s\" % (batchY[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PRINT CHARS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUT OF BATCHX:   [12 16 17  0 11 18  0  4  5 12] => ['h', 'o', 'n', ' ', 'i', 's', ' ', 'a', 'c', 'h']\n",
      "BATCHY (TARGET): [11, 16, 17, 0, 11, 18, 0, 4, 5, 12]\n",
      "\n",
      "OUT OF BATCHX:   [21 12  0 21  8  8  1  0  6 20] => ['t', 'h', ' ', 't', 'd', 'd', ',', ' ', 'b', 'u']\n",
      "BATCHY (TARGET): [21, 16, 0, 4, 8, 8, 1, 0, 6, 20]\n",
      "\n",
      "OUT OF BATCHX:   [ 7 10 21  0 21 16  0 21  4 13] => ['e', 'f', 't', ' ', 't', 'o', ' ', 't', 'a', 'k']\n",
      "BATCHY (TARGET): [7, 10, 21, 0, 21, 16, 0, 21, 4, 13]\n",
      "\n",
      "OUT OF BATCHX:   [21 18  0 17 16 21 12 11 17  9] => ['t', 's', ' ', 'n', 'o', 't', 'h', 'i', 'n', 'g']\n",
      "BATCHY (TARGET): [11, 18, 0, 17, 16, 21, 12, 11, 17, 9]\n",
      "\n",
      "OUT OF BATCHX:   [ 1  0  6 16 21  0 22 12  7 17] => [',', ' ', 'b', 'o', 't', ' ', 'w', 'h', 'e', 'n']\n",
      "BATCHY (TARGET): [1, 0, 17, 16, 21, 0, 22, 12, 7, 17]\n",
      "\n",
      "OUT OF BATCHX:   [21 12  0 21  4 13  7  0  4 22] => ['t', 'h', ' ', 't', 'a', 'k', 'e', ' ', 'a', 'w']\n",
      "BATCHY (TARGET): [21, 16, 0, 21, 4, 13, 7, 0, 4, 22]\n",
      "\n",
      "OUT OF BATCHX:   [21  0 22 12  7 17  0 21 12  7] => ['t', ' ', 'w', 'h', 'e', 'n', ' ', 't', 'h', 'e']\n",
      "BATCHY (TARGET): [21, 0, 22, 12, 7, 17, 0, 21, 12, 7]\n",
      "\n",
      "OUT OF BATCHX:   [21  7  0 21 16  0  4  8  8  1] => ['t', 'e', ' ', 't', 'o', ' ', 'a', 'd', 'd', ',']\n",
      "BATCHY (TARGET): [19, 7, 0, 21, 16, 0, 4, 8, 8, 1]\n",
      "\n",
      "OUT OF BATCHX:   [ 0 11 18  0 17 16 21 12 11 17] => [' ', 'i', 's', ' ', 'n', 'o', 't', 'h', 'i', 'n']\n",
      "BATCHY (TARGET): [0, 11, 18, 0, 17, 16, 21, 12, 11, 17]\n",
      "\n",
      "OUT OF BATCHX:   [21 21  8  8  1  0  6 20 21  0] => ['t', 't', 'd', 'd', ',', ' ', 'b', 'u', 't', ' ']\n",
      "BATCHY (TARGET): [0, 4, 8, 8, 1, 0, 6, 20, 21, 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "randidx = np.random.randint(low=0, high=ndata, size=batch_size)\n",
    "batchX = [dataX[iii] for iii in randidx]\n",
    "batchY = [dataY[iii] for iii in randidx]\n",
    "feeds = {X: batchX}\n",
    "results = sess.run(outputs, feed_dict=feeds)\n",
    "for j, result in enumerate(results):\n",
    "    index = np.argmax(result, axis=1)\n",
    "    chars = [char_set[t] for t in index]\n",
    "    if j < 10:\n",
    "        print (\"OUT OF BATCHX:   %s => %s\" % (index, chars))\n",
    "        print (\"BATCHY (TARGET): %s\\n\" % (batchY[j]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAMPLING FUNCTION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XL    LOOKS LIKE Tensor(\"Placeholder_2:0\", shape=(?, 1), dtype=int32)\n",
      "XL_OH LOOKS LIKE Tensor(\"one_hot_1:0\", shape=(?, 1, 25), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "LEN = 1 # <= LENGHT IS 1 !!\n",
    "# XL = tf.placeholder(tf.int32, [None, LEN])\n",
    "XL     = tf.placeholder(tf.int32, [None, 1])\n",
    "XL_OH  = tf.one_hot(XL, num_classes)\n",
    "with tf.variable_scope('CHAR-RNN', reuse=True):\n",
    "    cell_L = rnn.BasicLSTMCell(hidden_size, state_is_tuple=True, reuse=True)\n",
    "    # cell_L = rnn.MultiRNNCell([cell_L] * 2, state_is_tuple=True) # BUG IN TF1.1\n",
    "    istate = cell_L.zero_state(batch_size=1, dtype=tf.float32)\n",
    "    # DYNAMIC RNN WITH FULLY CONNECTED LAYER\n",
    "    _hiddens  = tf.contrib.layers.fully_connected(XL_OH, hidden_size, activation_fn=tf.nn.relu)\n",
    "    _outputs_L, states_L = tf.nn.dynamic_rnn(cell_L, _hiddens\n",
    "                                , initial_state=istate, dtype=tf.float32)\n",
    "    _outputs_L  = tf.contrib.layers.fully_connected(\n",
    "        _outputs_L, num_classes, activation_fn=None)\n",
    "    # RESHAPE FOR SEQUNCE LOSS\n",
    "    outputs_L = tf.reshape(_outputs_L, [LEN, 1, num_classes])\n",
    "print (\"XL    LOOKS LIKE %s\" % (XL))\n",
    "print (\"XL_OH LOOKS LIKE %s\" % (XL_OH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HELPER FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_pick(weights):\n",
    "    t = np.cumsum(weights)\n",
    "    s = np.sum(weights)\n",
    "    return(int(np.searchsorted(t, np.random.rand(1)*s)))\n",
    "def softmax(x):\n",
    "    alpha = 1\n",
    "    e_x = np.exp(alpha*(x - np.max(x)))\n",
    "    return e_x / np.sum(e_x) # only difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAMPLE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BURNIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] -char:  P \n",
      "    -inval: [[3]] \n",
      "    -outval: [[[ -3.08020091  -2.35454082  -2.51301169  -3.17741561  -2.92541146\n",
      "    -5.78698063   1.06790924  12.32919025  -6.53671503   2.24559045\n",
      "    -0.23400514   4.69022512   1.29558206  -2.14247799  -0.26732731\n",
      "     0.30243468   3.60911059  -1.01301849  -3.98470902   0.82241881\n",
      "    -8.28079796  -0.18096907  -1.79957652  -5.48043156  -0.57275331]]] \n",
      "[1] -char:  e \n",
      "    -inval: [[7]] \n",
      "    -outval: [[[  2.90841818  -3.15261364  -5.26657581  -2.76032543  -5.69346333\n",
      "     3.46740174  -0.99838358   2.42937207   4.03632069   0.44059879\n",
      "     7.37859058  -4.35361147  -1.64185107  -1.93758237  -4.03283739\n",
      "    -4.43539476  -5.94669437   5.06936741  -5.20767164  14.28791046\n",
      "    -1.07765269  -1.04316759  -6.34071636   5.14418316  -3.26660395]]] \n",
      "[2] -char:  r \n",
      "    -inval: [[19]] \n",
      "    -outval: [[[  4.48692799  -1.21608675  -5.32355404  -2.51072145  -7.60606241\n",
      "     2.06190777  -5.92302847  10.31890488   1.89060163  -1.53012657\n",
      "    16.06913948   2.20325446   1.27707517  -3.50660014  -5.17535257\n",
      "    -5.11694479  -2.82566643  -5.46365404  -5.0506587    4.45155287\n",
      "    -9.47616386   0.8011331   -9.68179512  -1.39607596  -2.67920589]]] \n"
     ]
    }
   ],
   "source": [
    "prime = \"Perfection is\"\n",
    "istateval = sess.run(cell_L.zero_state(1, tf.float32))\n",
    "for i, c in enumerate(prime[:-1]):\n",
    "    index = char_dic[c]\n",
    "    inval = [[index]]\n",
    "    outval, stateval = sess.run([outputs_L, states_L]\n",
    "                        , feed_dict={XL:inval, istate:istateval})\n",
    "    istateval = stateval # UPDATE STATE MANUALLY!!\n",
    "    if i < 3:\n",
    "        print (\"[%d] -char:  %s \\n    -inval: %s \\n    -outval: %s \" \n",
    "               % (i, c, inval, outval))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAMPLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] \n",
      " -inval: [[0]] \n",
      " -outval: [[[  1.91947448  -3.7294488   -1.18163824  -2.31040144  13.51008797\n",
      "    -2.56648397   0.63045412  -0.56764245  -4.33099174  -4.37447071\n",
      "    -7.52064991   1.96726823  -0.72000146  -5.25976324   0.30930054\n",
      "     0.08798702   2.4407711    4.32700539  -1.58308876  -5.40037489\n",
      "    -5.36968231   1.45565033   3.33320498  -3.09893799  -0.98546827]]] \n",
      " -index: 4 (char: a) \n",
      " -chars:  a\n",
      "[1] \n",
      " -inval: [[4]] \n",
      " -outval: [[[ -0.14383642  -1.11709249   0.15476504  -1.82591987   1.68663216\n",
      "    14.28822708  -0.88725519  -3.34232259   5.69124222  -1.5407052\n",
      "    -3.50985885 -11.68089104   2.6237607    2.44011259  -1.07054639\n",
      "    -1.42917883   2.69174647   1.92260468   1.94160521  -2.04601884\n",
      "     2.52123785  -3.39278913   1.23125076   1.36892271   2.04283261]]] \n",
      " -index: 5 (char: c) \n",
      " -chars:  ac\n",
      "[2] \n",
      " -inval: [[5]] \n",
      " -outval: [[[  2.96251321  -7.23301744  -2.77196884  -2.63052106   1.21266544\n",
      "    -1.01473677  -3.11380339  -0.32464457  -2.0736959    0.48602808\n",
      "     2.26947927  -1.21738338  13.56157112   0.50779712  -2.90734339\n",
      "    -3.38435078   1.12632     -5.96665859  -5.21542072  -3.51472425\n",
      "    -2.74900794   3.65701532  -6.61328793  -2.33343101  -2.34598923]]] \n",
      " -index: 12 (char: h) \n",
      " -chars:  ach\n",
      "[3] \n",
      " -inval: [[12]] \n",
      " -outval: [[[ -0.59917945  -4.36758757  -3.06501412  -4.36169434  -0.36728776\n",
      "    -7.74928761  -4.19774199   8.21453953  -9.12218094  -1.91916561\n",
      "     1.60031497  18.5041008    4.47089767  -4.98663664  -2.01500487\n",
      "    -1.56304002   0.59137398   0.35077459  -4.40200615  -2.93849277\n",
      "   -13.03035545   2.68474984  -2.19538093  -2.85704994  -5.3983779 ]]] \n",
      " -index: 11 (char: i) \n",
      " -chars:  achi\n",
      "[4] \n",
      " -inval: [[11]] \n",
      " -outval: [[[ -1.01138055  -3.57519007  -0.48061687  -4.29367638  -1.50905693\n",
      "    -3.61963534  -3.50817871  15.59158707  -3.13029313  -1.04685259\n",
      "    -2.54348063   5.34178114  -3.31979442  -4.44382524  -2.75544786\n",
      "    -2.44492841   4.80431557   5.73330545   4.2342391   -2.86234903\n",
      "    -9.48251152  -5.95674229   0.34430492  -0.35193393  -0.73896253]]] \n",
      " -index: 7 (char: e) \n",
      " -chars:  achie\n"
     ]
    }
   ],
   "source": [
    "inval  = [[char_dic[prime[-1]]]]\n",
    "outval, stateval = sess.run([outputs_L, states_L]\n",
    "                    , feed_dict={XL:inval, istate:istateval})\n",
    "istateval = stateval\n",
    "index = np.argmax(outval)\n",
    "char  = char_set[index]\n",
    "chars = char\n",
    "for i in range(100):\n",
    "    inval = [[index]]\n",
    "    outval, stateval = sess.run([outputs_L, states_L]\n",
    "                        , feed_dict={XL:inval, istate:istateval})\n",
    "    istateval = stateval\n",
    "    # index = np.argmax(outval)\n",
    "    index = weighted_pick(softmax(outval))\n",
    "    char  = char_set[index]\n",
    "    chars += char\n",
    "    if i < 5:\n",
    "        print (\"[%d] \\n -inval: %s \\n -outval: %s \\n -index: %d (char: %s) \\n -chars: %s\" \n",
    "               % (i, inval, outval, index, char, chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAMPLED SENTENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SAMPLED SETENCE> \n",
      " Perfection is achieved, not when there is nothing left to take away..y.ed, but when there is nothing more to add, \n",
      "\n",
      "<ORIGINAL SENTENCE> \n",
      " Perfection is achieved, not when there is nothing more to add, but when there is nothing left to take away.\n"
     ]
    }
   ],
   "source": [
    "print (\"<SAMPLED SETENCE> \\n %s\" % (prime+chars))\n",
    "print (\"\\n<ORIGINAL SENTENCE> \\n %s\" % (sentence))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
